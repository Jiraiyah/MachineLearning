{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NEURAL_NETWORKS.jpg)\n",
    "\n",
    "# Simple MNIST\n",
    "## Done By : Alireza Khodakarami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "We need pickle to read pre-processed data from hard drive, and cv2 to read and tweak test data at the end. The rest is tensor flow and possible needs for defining our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "We read binary pre-processed data from hard drive and assign them to X and y respectedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('./Data/PetImages/X.pickle', 'rb')\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('./Data/PetImages/y.pickle', 'rb')\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "\n",
    "We still need to normalize the input data to make them sit between 0 - 1. We could have used the utils function from tensor flow but wanted to show you another way of doing it on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print The Shape\n",
    "\n",
    "Always a good idea of printing the shape before model definition. We need to introduce the shape in first neural layer (we can ignore it but then we could not use model.summary). Knowing the shape can help putting the proper code on the first layer within model definition. The first element is the number of data. Tesorflow don't care about the number of data but the rest of the shape is really important else, it would fail accepting the data as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24946, 150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "Finally we define a convolutional neural network. After conv2D layers, we need a flatten layer. The last layer is a single output node. We don't need more than one because our classification is a binary format, we either have dog or cat (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 148, 148, 256)     2560      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 148, 148, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 74, 74, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 72, 72, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 72, 72, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 331776)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 331777    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 924,417\n",
      "Trainable params: 924,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Fitting Params\n",
    "\n",
    "This is one of my personal habbits. I prefer to have a dedicated section for parameters I use on model training. It makes it easier for me to read and later on, tweak these params if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "VALIDAITON_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "\n",
    "Finally we send in the inputs and labels for the model to train itself on as many epochs as we think we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/30\n",
      "22451/22451 [==============================] - 64s 3ms/sample - loss: 0.6280 - acc: 0.6461 - val_loss: 0.7818 - val_acc: 0.5407\n",
      "Epoch 2/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.5248 - acc: 0.7401 - val_loss: 0.6284 - val_acc: 0.6890\n",
      "Epoch 3/30\n",
      "22451/22451 [==============================] - 65s 3ms/sample - loss: 0.4701 - acc: 0.7750 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 4/30\n",
      "22451/22451 [==============================] - 65s 3ms/sample - loss: 0.4263 - acc: 0.8040 - val_loss: 0.5426 - val_acc: 0.7507\n",
      "Epoch 5/30\n",
      "22451/22451 [==============================] - 64s 3ms/sample - loss: 0.3987 - acc: 0.8176 - val_loss: 0.5092 - val_acc: 0.7543\n",
      "Epoch 6/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.3690 - acc: 0.8373 - val_loss: 0.5007 - val_acc: 0.7844\n",
      "Epoch 7/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.3381 - acc: 0.8543 - val_loss: 0.6847 - val_acc: 0.6922\n",
      "Epoch 8/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.3060 - acc: 0.8678 - val_loss: 1.1134 - val_acc: 0.5643\n",
      "Epoch 9/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.2756 - acc: 0.8833 - val_loss: 0.6842 - val_acc: 0.7214\n",
      "Epoch 10/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.2501 - acc: 0.8960 - val_loss: 0.6906 - val_acc: 0.7359\n",
      "Epoch 11/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.2228 - acc: 0.9079 - val_loss: 0.8255 - val_acc: 0.7106\n",
      "Epoch 12/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.2010 - acc: 0.9173 - val_loss: 0.5590 - val_acc: 0.7944\n",
      "Epoch 13/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1786 - acc: 0.9298 - val_loss: 0.9525 - val_acc: 0.6938\n",
      "Epoch 14/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1557 - acc: 0.9384 - val_loss: 0.8542 - val_acc: 0.7343\n",
      "Epoch 15/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1376 - acc: 0.9475 - val_loss: 1.3122 - val_acc: 0.6509\n",
      "Epoch 16/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1237 - acc: 0.9526 - val_loss: 0.9908 - val_acc: 0.7419\n",
      "Epoch 17/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1140 - acc: 0.9566 - val_loss: 1.3349 - val_acc: 0.6898\n",
      "Epoch 18/30\n",
      "22451/22451 [==============================] - 62s 3ms/sample - loss: 0.1057 - acc: 0.9597 - val_loss: 1.0880 - val_acc: 0.7475\n",
      "Epoch 19/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0879 - acc: 0.9677 - val_loss: 1.2185 - val_acc: 0.7331\n",
      "Epoch 20/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0738 - acc: 0.9752 - val_loss: 1.3272 - val_acc: 0.7218\n",
      "Epoch 21/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0720 - acc: 0.9748 - val_loss: 1.5461 - val_acc: 0.7070\n",
      "Epoch 22/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0667 - acc: 0.9758 - val_loss: 1.6156 - val_acc: 0.7086\n",
      "Epoch 23/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0638 - acc: 0.9766 - val_loss: 1.7899 - val_acc: 0.6938\n",
      "Epoch 24/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0654 - acc: 0.9774 - val_loss: 1.8049 - val_acc: 0.6922\n",
      "Epoch 25/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0516 - acc: 0.9825 - val_loss: 1.6579 - val_acc: 0.7283\n",
      "Epoch 26/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0492 - acc: 0.9823 - val_loss: 1.7443 - val_acc: 0.7126\n",
      "Epoch 27/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0515 - acc: 0.9821 - val_loss: 1.6982 - val_acc: 0.7263\n",
      "Epoch 28/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0364 - acc: 0.9888 - val_loss: 1.6170 - val_acc: 0.7535\n",
      "Epoch 29/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0400 - acc: 0.9868 - val_loss: 1.7060 - val_acc: 0.7359\n",
      "Epoch 30/30\n",
      "22451/22451 [==============================] - 63s 3ms/sample - loss: 0.0383 - acc: 0.9865 - val_loss: 2.0996 - val_acc: 0.7082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f174a21a90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "         batch_size = BATCH_SIZE,\n",
    "         epochs = EPOCHS,\n",
    "         validation_split = VALIDAITON_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "At the end of each training session we save the model so that we won't loose trained model by any accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Models/03 - Convolutional.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "\n",
    "In one single training session you won't need this. But if you are planning on training your model for many days, there is a high chance that you would want to turn off the pc, and next day continue the job. Having this section lets you load the previously saved model and save yourself the troble of reteaching the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./Models/03 - Convolutional.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pre-Processing\n",
    "\n",
    "We need to mimic the pre-processing functionality for any test image we want to use after training our model.\n",
    "\n",
    "Here we define a function, we send in the path of the image in and we get the reshaped ready to use data back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Dog', 'Cat']\n",
    "\n",
    "def prepare(filepath):\n",
    "    img_size = 150\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "    return new_array.reshape(-1, img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Prediction\n",
    "\n",
    "Never trust the accuracy and loss value you get on the training session being it on the training data or on the validation data. You may get a good and high result there but with producing new images by yourself (something that the network never saw) you may be suprised how poor your network's prediction can become. The reverse can be true too. The result on training may not be that high and nice but the network would predict your sample tests very well. Long story short, after each training session, test your network with unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a01 - should be human, prediction : Dog\n",
      "c01 - should be cat, prediction : Cat\n",
      "c02 - should be cat, prediction : Cat\n",
      "c03 - should be cat, prediction : Cat\n",
      "d01 - should be dog, prediction : Dog\n",
      "d02 - should be dog, prediction : Dog\n",
      "d03 - should be dog, prediction : Dog\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('./Data/Test/a01.jpg')])\n",
    "print('a01 - should be human, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/c01.jpg')])\n",
    "print('c01 - should be cat, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/c02.jpeg')])\n",
    "print('c02 - should be cat, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/c03.jpg')])\n",
    "print('c03 - should be cat, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/d01.png')])\n",
    "print('d01 - should be dog, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/d02.jpg')])\n",
    "print('d02 - should be dog, prediction :',categories[int(prediction[0][0])])\n",
    "\n",
    "prediction = model.predict([prepare('./Data/Test/d03.jpg')])\n",
    "print('d03 - should be dog, prediction :',categories[int(prediction[0][0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
